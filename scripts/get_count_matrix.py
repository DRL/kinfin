#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
usage: get_count_matrix.py           -g <FILE> -s <FILE> -c <FILE> [-u <FILE>] [-t <FILE>] [-i <FILE>]
                                    [-f <FILE>] [-x <FILE] [-o <STR>]
                                    [-h|--help]

    Options:
        -h --help                               show this
        -g, --groups <FILE>                     OrthologousGroups.txt produced by OrthoFinder
        -c, --config <FILE>                     Config file used in KinFin
        -s, --sequence_ids <FILE>               SequenceIDs.txt used for OrthoFinder
        -u, --cluster_ids <FILE>                List of cluster ids (one cluster ID per line)
        -t, --target_ids <FILE>                 List of protein/gene ids (CSV; protein_id,name,description)

        -f, --functional_annotation <FILE>      cluster_functional_annotation.all.*.txt (generated by functional_annotation_of_clusters.py)
        -i, --protein_ids_by_gene_id <FILE>     Protein ids by gene id (generated by filter_isoforms_based_on_gff3.py)
        -x, --taxon_order <FILE>                Taxon order file (one line per taxon), otherwise alphabetical order.
        -o, --outprefix <STRING>                Output prefix
"""
import re
import sys
import operator
from docopt import docopt
import collections
import os


def read_file(infile):
    if not infile or not os.path.exists(infile):
        sys.exit("[X] - File '%s' does not exist." % (infile))
    print("[+] Parsing %s ..." % (infile))
    with open(infile) as fh:
        for line in fh:
            line = line.replace(r'\r', '\n')
            if not line.startswith("#"):
                yield line.rstrip("\n")


def write_file(out_f, outprefix, header, strings):
    if outprefix:
        if outprefix.endswith("/"):
            if not os.path.exists(outprefix):
                os.mkdir(outprefix)
            out_f = "%s" % os.path.join(outprefix, out_f)
        else:
            out_f = "%s.%s" % (outprefix, out_f)
    print("[+] \t Writing file %s ..." % (out_f))
    with open(out_f, 'w') as out_fh:
        out_fh.write("%s\n" % (header))
        out_fh.write("%s\n" % "\n".join(strings))


class TargetObj():
    def __init__(self, sequence_id, sequence_name, sequence_description):
        self.sequence_id = sequence_id
        self.sequence_name = sequence_name
        self.sequence_description = sequence_description
        self.protein_ids = set()
        self.found_protein_ids = set()
        self.found_protein_ids_count = 0
        self.cluster_ids_found = 0
        self.protein_ids_by_cluster_id = {}

    def add_protein_id(self, protein_id):
        self.protein_ids.add(protein_id)

    def add_match(self, cluster_id, protein_id):
        if cluster_id not in self.protein_ids_by_cluster_id:
            self.protein_ids_by_cluster_id[cluster_id] = []
            self.cluster_ids_found += 1
        self.protein_ids_by_cluster_id[cluster_id].append(protein_id)
        self.found_protein_ids_count += 1
        self.found_protein_ids.add(protein_id)


class ClusterObj():
    def __init__(self, cluster_id, protein_ids):
        self.cluster_id = cluster_id
        self.protein_ids = set(protein_ids)
        self.domain_ids = ''
        self.domain_descriptions = ''
        self.protein_count = len(protein_ids)
        self.protein_count_by_taxon_id = collections.Counter()
        self.taxon_count = 0
        self.target_protein_ids = set()

    def add_taxon_counter(self, taxon_counter):
        self.protein_count_by_taxon_id = taxon_counter
        self.taxon_count = len(taxon_counter)

    def add_domains(self, domain_ids, domain_descriptions):
        self.domain_ids = domain_ids
        self.domain_descriptions = domain_descriptions

    def add_protein_ids_of_interest(self, protein_ids_of_interest):
        for protein_id in protein_ids_of_interest:
            self.target_protein_ids.add(protein_id)


class DataCollection():
    def __init__(self, args):
        self.groups_f = args['--groups']
        self.outprefix = args['--outprefix']

        self.config_f = args['--config']
        self.taxon_id_by_idx = {}
        self.parse_config_f()

        self.sequence_id_f = args['--sequence_ids']
        self.taxon_id_by_protein_id = {}
        self.parse_sequence_id_f()

        self.cluster_id_f = args['--cluster_ids']
        self.target_id_f = args['--target_ids']
        self.protein_ids_by_gene_id_f = args['--protein_ids_by_gene_id']

        if not self.cluster_id_f and not self.target_id_f:
            sys.exit("[X] - Please specify either '--cluster_ids' or '--target_ids'")

        self.targetCluster_by_cluster_id = {}
        if self.cluster_id_f:
            self.parse_cluster_ids_f()

        self.targetObj_by_target_id = {}
        self.target_id_by_protein_id = {}
        if self.target_id_f:
            if self.protein_ids_by_gene_id_f:
                self.parse_target_id_f('gene_ids')
                self.parse_protein_ids_by_gene_id_f()
            else:
                self.parse_target_id_f('protein_ids')

        self.parse_groups_f()
        self.functional_annotation_f = args['--functional_annotation']
        if self.functional_annotation_f:
            self.parse_functional_annotation_f()
        self.taxon_order_f = args['--taxon_order']
        self.taxon_order = []
        if self.taxon_order_f:
            self.parse_taxon_order_f()
        else:
            self.taxon_order = sorted(self.taxon_id_by_idx.values())

        # output
        if self.protein_ids_by_gene_id_f:
            self.write_gene_stats()
            self.write_protein_matrix()
        elif self.target_id_f:
            self.write_protein_matrix()
        else:
            pass
        self.write_cluster_matrix()

    def write_protein_matrix(self):
        out_f = "protein_matrix.tsv"
        header = ['#protein_id', 'gene_name', 'gene_description', 'cluster_id', 'protein_count', 'taxon_count']
        for taxon_id in self.taxon_order:
            header.append(taxon_id)
        header.append('domain_ids')
        header.append('domain_descriptions')
        header = "\t".join(header)
        output = []
        for target_id, targetObj in self.targetObj_by_target_id.items():
            for cluster_id, protein_ids in targetObj.protein_ids_by_cluster_id.items():
                clusterObj = self.targetCluster_by_cluster_id[cluster_id]
                for protein_id in protein_ids:
                    line = []
                    line.append(protein_id)
                    line.append(targetObj.sequence_name)
                    line.append(targetObj.sequence_description)
                    line.append(clusterObj.cluster_id)
                    line.append(clusterObj.protein_count)
                    line.append(clusterObj.taxon_count)
                    for taxon_id in self.taxon_order:
                        taxon_count = clusterObj.protein_count_by_taxon_id.get(taxon_id, 0)
                        line.append(taxon_count)
                    line.append(clusterObj.domain_ids)
                    line.append(clusterObj.domain_descriptions)
                    output.append("\t".join([str(x) for x in line]))
        write_file(out_f, self.outprefix, header, output)

    def write_cluster_matrix(self):
        out_f = "cluster_matrix.tsv"
        header = ['#cluster_id', 'target_gene_ids', 'target_protein_ids', 'protein_count', 'taxon_count']
        for taxon_id in self.taxon_order:
            header.append(taxon_id)
        header.append('domain_ids')
        header.append('domain_descriptions')
        header = "\t".join(header)
        output = []
        for cluster_id, clusterObj in self.targetCluster_by_cluster_id.items():
            target_protein_ids = clusterObj.target_protein_ids
            target_gene_ids = [self.target_id_by_protein_id[protein_id] for protein_id in target_protein_ids]
            line = []
            line.append(cluster_id)
            line.append(",".join(target_gene_ids))
            line.append(",".join(target_protein_ids))
            line.append(clusterObj.protein_count)
            line.append(clusterObj.taxon_count)
            for taxon_id in self.taxon_order:
                taxon_count = clusterObj.protein_count_by_taxon_id.get(taxon_id, 0)
                line.append(taxon_count)
            line.append(clusterObj.domain_ids)
            line.append(clusterObj.domain_descriptions)
            output.append("\t".join([str(x) for x in line]))
        write_file(out_f, self.outprefix, header, output)

    def write_gene_stats(self):
        out_f = "gene_stats.tsv"
        header = "\t".join(['#gene_id', 'gene_name', 'gene_description', 'total_proteins', 'protein_ids', 'protein_ids_found', 'cluster_ids', 'cluster_ids_found'])
        output = []
        for target_id, targetObj in self.targetObj_by_target_id.items():
            line = []
            line.append(targetObj.sequence_id)
            line.append(targetObj.sequence_name)
            line.append(targetObj.sequence_description)
            line.append(len(targetObj.protein_ids))
            if targetObj.found_protein_ids:
                line.append(",".join(sorted(targetObj.found_protein_ids)))
            else:
                line.append("None")
            line.append(len(targetObj.found_protein_ids))
            if targetObj.protein_ids_by_cluster_id:
                line.append(",".join([cluster_id for cluster_id in targetObj.protein_ids_by_cluster_id.keys()]))
            else:
                line.append("None")
            line.append(targetObj.cluster_ids_found)
            output.append("\t".join([str(x) for x in line]))
        write_file(out_f, self.outprefix, header, output)

    def parse_config_f(self):
        for line in read_file(self.config_f):
            col = line.split(",")
            taxon_idx = col[0]
            taxon = col[1]
            self.taxon_id_by_idx[taxon_idx] = taxon

    def parse_sequence_id_f(self):
        for line in read_file(self.sequence_id_f):
            col = line.split(": ")
            taxon_idx = col[0].split("_")[0]
            protein_id = col[1].replace(":", "_").replace(",", "_").replace("(", "_").replace(")", "_")  # behaviour like Orthofinder
            self.taxon_id_by_protein_id[protein_id] = self.taxon_id_by_idx[taxon_idx]

    def parse_target_id_f(self, arg):
        for line in read_file(self.target_id_f):
            col = line.split(",")
            sequence_id = col[0]
            sequence_name = col[1]
            sequence_description = col[2]
            self.targetObj_by_target_id[sequence_id] = TargetObj(sequence_id, sequence_name, sequence_description)
            if arg == "protein_ids":
                self.target_id_by_protein_id[sequence_id] = sequence_id

    def parse_cluster_ids_f(self):
        for line in read_file(self.cluster_id_f):
            self.targetCluster_by_cluster_id[line] = None

    def parse_protein_ids_by_gene_id_f(self):
        for line in read_file(self.protein_ids_by_gene_id_f):
            col = line.split("\t")
            gene_id = col[0]
            protein_string = col[1].split(",")
            if gene_id in self.targetObj_by_target_id:
                for protein_id in protein_string:
                    self.target_id_by_protein_id[protein_id] = gene_id
                    self.targetObj_by_target_id[gene_id].add_protein_id(protein_id)

    def parse_functional_annotation_f(self):
        for line in read_file(self.functional_annotation_f):
            col = line.split("\t")
            cluster_id = col[0]
            domain_ids = col[3]
            domain_descriptions = col[4]
            if cluster_id in self.targetCluster_by_cluster_id:
                self.targetCluster_by_cluster_id[cluster_id].add_domains(domain_ids, domain_descriptions)

    def parse_groups_f(self):
        for line in read_file(self.groups_f):
            cluster_id, protein_string = line.rstrip("\n").split(": ")
            protein_ids = protein_string.split(" ")
            clusterObj = ClusterObj(cluster_id, protein_ids)
            if self.cluster_id_f:
                # looking for cluster_ids
                if cluster_id in self.targetCluster_by_cluster_id:
                    taxon_counter = collections.Counter([self.taxon_id_by_protein_id[protein_id] for protein_id in clusterObj.protein_ids])
                    clusterObj.add_taxon_counter(taxon_counter)
                    self.targetCluster_by_cluster_id[cluster_id] = clusterObj
            else:
                protein_ids_of_interest = clusterObj.protein_ids.intersection(self.target_id_by_protein_id.keys())
                if protein_ids_of_interest:
                    taxon_counter = collections.Counter([self.taxon_id_by_protein_id[protein_id] for protein_id in clusterObj.protein_ids])
                    clusterObj.add_taxon_counter(taxon_counter)
                    clusterObj.add_protein_ids_of_interest(protein_ids_of_interest)
                    self.targetCluster_by_cluster_id[cluster_id] = clusterObj
                    for protein_id in protein_ids_of_interest:
                        target_id = self.target_id_by_protein_id[protein_id]
                        self.targetObj_by_target_id[target_id].add_match(cluster_id, protein_id)

    def parse_taxon_order_f(self):
        for line in read_file(self.taxon_order_f):
            self.taxon_order.append(line)

    def parse_target_cluster_id_f(self, target_cluster_id_f):
        for line in read_file(target_cluster_id_f):
            cluster_id = line
            self.cluster_ids.append(cluster_id)
            self.clusterObj_by_cluster_id[cluster_id] = {}


if __name__ == "__main__":
    __version__ = 0.2
    args = docopt(__doc__)
    print("[+] Start ...")
    dataCollection = DataCollection(args)
